---
title: "Fuga_de_Clientes"
author: "Laura Piñeros"
date: "Febrero 2022"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Estudio descriptivo de datos sobre Fuga de Clientes


```{r cars, warning=FALSE, results='hide', message=FALSE}
#Ruta de Funciones 
getwd()
setwd('C:/Users/Laura/Dropbox/UCM/Mineria_y_modelizacion_1/Tarea')

#cargamos las funciones
source('Funciones_R.R')


#Leer los datos training de Fuga de Clientes 
datos <- readRDS('C:/Users/Laura/Dropbox/UCM/Mineria_y_modelizacion_1/Tarea/FugaClientes_Training.RDS')

#cargamos librerias 
paquetes(c('questionr','psych','car','corrplot','ggplot2',"gridExtra",'kableExtra','dplyr','DMwR2'))
```
Se presenta la siguiente tabla con la información detallada de cada uno de los campos del dataset. 

![Fig1. Descripción de los datos](C:/Users/Laura/Desktop/UCM/Documentacion2/Tarea/fuga_clientes.png)

A continuación se comprobarán y se análizarán los tipos de variables, los valores fuera de rango, se definirán variables nominales, Outliers y Missings.


```{r}
str(datos)
```
#Note que: 
  - Tenemos 6353 registros y 21 variables 
  - la mayoría de las variables son de tipo nominales 
  - La variable Mayor65 y Fuga son de tipo nominales(Dicotómicas)
  - Las variables tienen el tipo correcto de datos.
  - Cambiamos nombre de la variable Antiguedad 
  - Transformamos ID como caracter(Si la dejamos como factor nos puede traer problemas para el modelo )
  - Nuestro modelo consumirá $k-1$ parámetros siendo $k$ el número de niveles del factor. 

```{r}
#Transformación de variables 
datos$ID <- as.numeric(datos$ID)
names(datos)[6]<-"Antiguedad"
names(datos)
str(datos)
```

```{r}
#Número de valores diferentes para las variables continuas
sapply(Filter(is.numeric, datos),function(x) length(unique(x)))

#Distribución de las variables 
summary(datos)

# Ver el reparto de las categorías de las variables cualitativas
questionr::freq(datos$MetodoPago)
questionr::freq(datos$Contrato)

#Describe variables numéricas 
psych::describe(Filter(is.numeric, datos))
```
##Visualización del dataset 

```{r, warning=FALSE}
# Inspección gráfica inicial
listaGraf <- dfplot_box(datos) #Boxplots variables numéricas
listaHist<-dfplot_his(datos) #Histogramas variables categóricas 

# para presentar una rejilla de graficos a nuestro gusto
gridExtra::marrangeGrob(listaGraf, nrow = 4, ncol = 3)
gridExtra::marrangeGrob(listaHist, nrow = 4, ncol = 3)

```

Una vez estudiados los datos y libres de errores, podemos trabajar con el archivo de predictores, teniendo en cuenta que la asimetría será un factor importante para nuestro estudio. 

##Gestión de outliers y Missing 

A continuación presentamos, separación de variables objetivo, ya que no es habitual trabajar con ellas. Así mismo, el conjunto de predictores en input, y tomamos como variable Objetivo Fuga de tipo nominal.  
```{r}
#separación variables objetivo
#conjunto de predictores input 
#Los atípicos y los missings se gestionan sólo de las input
#varObjCont<-datos$Beneficio#varaible objetivo continua
varObjBin<-datos$Fuga#variable objetivo binaria (la sacas del dataframe)
input<-as.data.frame(datos[,-(21)])#generas dataframe sin esas variables  
input$ID<-as.numeric(datos$ID)#para realizar comprobaciones 
```

##Valores atípicos 

Sabemos que los valores atípicos no son demasiado frecuentes y en efecto deben ser poco frecuentes para considerarlos atípicos,  llevamos a cabo un conteo de los valores que se consideran extremos según un consenso de dos criterios distintos.

```{r}
## Proporción de Atípicos
# Cuento el porcentaje de atípicos de cada variable. 
# Si son muchos, elimino esas 
# variables en la siguiente línea de código
sapply(Filter(is.numeric, input),
       function(x) atipicosAmissing(x)[[2]])/nrow(input)
#devuleve una lista de los atipicos convertidos a missing con el argumento 1 
#argumento 2 de tipo informativo , pues me dice que proporción hay (incidencia)



# data.frame para el % de atipicos por variable
t<-data.frame(sort(
  round(sapply(Filter(
    is.numeric, input),function(nOut) atipicosAmissing(
      nOut)[[2]])/nrow(input)*100,3), decreasing = T))
names(t)<-"% Outliers por variable"

# Formato normal
t

```
Ya que la incidencia es muy baja, practicamente nula pasamos a tratar los Valores perdidos. 

##Valores Perdidos 

Valoremos la incidencia que tienen los missings y veamos si existe algún patron de aparición de los mismos. En caso de que observemos patrones de aparición, esto nos ayudará a decidir el método más adecuado para imputar. 


```{r}
## MISSINGS
#Busco si existe algún patrón en los missings, que me pueda ayudar a entenderlos
corrplot(cor(is.na(input[colnames(
  input)[colSums(is.na(input))>0]])),method = "ellipse",type = "upper") 
```
El gráfico, está muy limpio podemos decir que no hay ningún patron de identificación. 

Ahora valoremos la incidencia de los valores perdidos ya que si no representan una gran proporción, no existirá  gran peligro de cambio en la distribución de las variables con independencia del método utilizado para la imputación.  

```{r}
#Missings por variable 
prop_missingsVars<-apply(is.na(input),2,mean) # Por variable

# Tabla bonita para el % de missing por variable
t<-data.frame(sort(prop_missingsVars*100, decreasing = T))
names(t)<-"% Missing por Variable"
t
```
Note que, Antiguedad, Contrato, FacturaMes, tienen la misma proporcion de Missings. Así mismo, Genero y Mayor65. 
Dado que estos valores NO representan una buena proporción por variable, no es necesartio recategorizar, 

- Missings por observación 

Calcularemos ahora el % de missings por observación y vamos a generar una variable en el archivo que cuenta la proporcion de perdidos que tiene cada regsitro. Dicha variable, la incluiremos en el modelo para valorar si puede generar un patrón de comportamiento respecto a la variable objetivo. 


```{r}
#Proporción de missings por variable y observación
input$prop_missings<-apply(is.na(input),1,mean) # Por observación
summary(input$prop_missings)
```
Ordenando el archivo por la nueva variable creada, tenemos que, 

```{r}
input %>% arrange(desc(prop_missings)) %>% slice_head(n=10)
```

Si eliminamos regsitros y observaciones con más de la mitad de su información perdida no habrá mucho cambio, pues no lo consideramos como una cantidad considerable. Cabe resaltar que, aplicamos el mismo filtro a las variable objetivo.  

```{r}
#elimino las observaciones y las variables con más de la mitad 
# de datos missings (si no hay ninguna, no ejecuto este código)
input %>% filter(prop_missings< 0.5) %>% select(!(names(
  prop_missingsVars)[prop_missingsVars>0.5]))-> imput 

#Actualizar las observaciones de las variables objetivo
varObjBin<-varObjBin[input$prop_missings<0.5] 
```


```{r}

## Imputaciones
# Imputo todas las cuantitativas, seleccionar el tipo 
# de imputación: media, mediana o aleatorio
input[,as.vector(which(sapply(input, class)=="numeric"))]<-sapply(
  Filter(is.numeric, input),function(x) ImputacionCuant(x,"aleatorio"))

# input[,as.vector(which(sapply(input, class)=="numeric"))]<-sapply(
#  Filter(is.numeric, input),function(x) Hmisc::impute(x,"random"))
```

Realizaremos la imputación simple teniendo en cuenta únicamente las distribuciones marginales de las variables. Así, 

```{r}
# Imputo todas las cualitativas, seleccionar el tipo
# de imputación: moda o aleatorio
# Si solo se quiere imputar una, variable<-ImputacionCuali(variable,"moda")
input[,as.vector(which(sapply(input, class)=="factor"))]<-sapply(
  Filter(is.factor, input),function(x) ImputacionCuali(x,"aleatorio"))

# A veces se cambia el tipo de factor a character al imputar, 
# así que hay que indicarle que es factor
input[,as.vector(which(sapply(input, class)=="character"))] <- lapply(
  input[,as.vector(which(sapply(input, class)=="character"))] , factor)

# Reviso que no queden datos missings
summary(input)
```
Es posible que quede algún missing sin imputar en variable numéricas, efectuamos el siguiente código viendo que no queden datos missings.  Una vez finalizado el proceso de depuración guardamos el archivo datosFugaClientes.RDS.

```{r}

if (any(is.na(input))){
input[,as.vector(which(sapply(input, class)=="numeric"))]<-sapply(
  Filter(is.numeric, input),function(x) ImputacionCuant(x,"aleatorio"))

summary(input)
}

# Una vez finalizado este proceso, se puede considerar 
# que los datos están depurados. Los guardamos
saveRDS(cbind(varObjBin,input),"datosFugaClientes.RDS")
#cbind() para unir las columnas 
```



## Aplicación del modelo 


En primer lugar se fija el directorio de trabajo donde tenemos las funciones y los datos.

```{r directorio y funciones, echo=FALSE, warning=F}
#Ruta de Funciones 
setwd('C:/Users/Laura/Dropbox/UCM/Mineria_y_modelizacion_1/Tarea')

#cargamos las funciones
source('Funciones_R.R')
```

```{r paquetes, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}

# Utilizamos la función paquetes
# para instalar/cargar las librerías
paquetes(c('questionr','psych','car','corrplot','caret', 
           'ggplot2', 'lmSupport','pROC','gridExtra', 'glmnet'))

```

Procedemos a la lectura de los datos depurados.


```{r lectura datos}
# Parto de los datos sin atípicos ni ausentes guardados
datos<-readRDS("C:/Users/Laura/Dropbox/UCM/Mineria_y_modelizacion_1/Tarea/datosFugaClientes.RDS")
#names(datos)
varObjBin<-datos$varObjBin
input<-datos[,-(1)]

```

Variables control:

```{r variables de control}
# Creo la variable aleatoria
input$aleatorio<-runif(nrow(input))
input$aleatorio2<-runif(nrow(input))
str(input)
```


## Estudio descriptivo de relaciones con la respuesta

En este apartado intentaremos descubrir a priori las relaciones marginales de las variables con la variable objetivo binaria para hacernos una idea de cuales de ellas serán potencialmente influyentes en los modelos de regresión logística que ajustemos. 

```{r Vcramer, warning=FALSE}
#Obtengo la importancia de las variables. 
#Falla si hay alguna variable cuantitativa con menos de 6 valores diferentes
input$prop_missings <-as.factor(input$prop_missings)
graficoVcramer(input,varObjBin)
```


Podemos decir que las variables tentativas para el modelado son:

- Contrato 
- Antiguedad
- Int_serv
- MetodoPago 

Después de aleatorio2  empezamos a sospechar que las relaciones con la variable objetivo si pueden ser casualidad. 

Veamos gráficamente la relacion entre las varaibles con la objetivo, por medio del mosaico. Tomemos una variable que ifluye y tomemos otra que no tanto a ver que nos resulta. 

```{r mosaicos, warning=FALSE}
#Veo gráficamente el efecto de dos variables cualitativas sobre la binaria
m1<-mosaico_targetbinaria(input$Peliculas,varObjBin,"Peliculas") #esta no influye 
m2<-mosaico_targetbinaria(input$Contrato,varObjBin,"Contrato") #esta sí influye

```

Para la variable peliculas, que no tiene mucha incidencia podemos ver que hay una mínima diferencia entre las regiones. Para la variable  Contrato, que consideramos tiene mucha incidencia con la variable objetivo, es más probable contrato con objetivo uno, cuando es mes a mes. Parece ser que, el contrato extendido por un año y hasta dos años, puede darnos indicio de fuga de clientes. 

Veamos que efecto tienen dos variables cuantitativas sobre la objetivo binaria.

```{r histogramas y boxplots, warning=FALSE, message=F}
#Veo gráficamente el efecto de dos variables cuantitativas sobre la binaria
bx1<-boxplot_targetbinaria(input$Antiguedad,varObjBin,"Antiguedad")
bx2<-boxplot_targetbinaria(input$FacturaMes,varObjBin,"FacturaMes")
bx4<-boxplot_targetbinaria(input$FacturaTotal,varObjBin,"FacturaTotal")


h1<-hist_targetbinaria(input$Antiguedad,varObjBin,"Antiguedad")
h2<-hist_targetbinaria(input$FacturaMes,varObjBin,"FacturaMes")
h4<-hist_targetbinaria(input$FacturaTotal,varObjBin,"FacturaTotal")

marrangeGrob(list(bx1,bx2,h1,h2),nrow = 2,ncol = 2)
marrangeGrob(list(bx4,h4),nrow = 1,ncol = 2)
```
Los graficos Vcramer nos intenta decir que, para clientes cuyo tiempo de antiguedad es apenas de unos meses, tienen mas probabilidad de Fuga. Aquellos clientes que se fugan(fuga=1) no presentan facturas tan altas. Deben tener un posible sesgo. 


## Tranformaciones de variables

Vamos a generar las transformaciones de las variable continuas que maximizan la relación con la variable objetivo binaria en sentido de V de Cramer. 

```{r transformaciones, warning=FALSE}
#Busco las mejores transformaciones para las variables numéricas con respesto a la variable binaria
input_bin<-cbind(input,Transf_Auto(Filter(is.numeric, input),varObjBin))

# Guardamos el dataset con las tranformaciones
todo_bin<-data.frame(input_bin,varObjBin)
saveRDS(todo_bin,"todo_bin_Fuga_Clientes.RDS")
```



```{r Vcramer tranformaciones, warning=FALSE}
#Obtengo la importancia de las variables. 
graficoVcramer(input_bin,varObjBin)
```
Tiene buena pinta, pues no hubo muchos cambios. Hasta acá, quisimos dar una breve descripción a los datos para encontar incidencias con la variable objetivo. 

##Modelo de regresión logistica para la predicción de la variable Fuga 

```{r}
#todo<-readRDS("todo_bin")
todo<-todo_bin

freq(todo$varObjBin) #ese ha de ser el error de referencia
```


Siguiendo las especificaciones del modelo, este tendrá mas dificultad en reconocer a los 1, es decir, los clientes en fuga. 

### Partición training-test

```{r}

#Hago la partición
set.seed(123456)
trainIndex <- createDataPartition(todo$varObjBin, p=0.8, list=FALSE)
data_train <- todo[trainIndex,c(1:23,30)]
data_test <- todo[-trainIndex,c(1:23,30)]
#data_test <- readRDS("C:/Users/Laura/Desktop/UCM/Documentacion2/Tarea/FugaClientes_test.RDS")
```


Quitemos los efectos no deseados o doblajes de las variables.

```{r modelo manual lineal}
# Este fue el modelo manual ganador 
modeloManual<-glm(varObjBin~Contrato+Int_serv+Antiguedad,
             data=data_train,family=binomial)
summary(modeloManual)
pseudoR2(modeloManual,data_train,"varObjBin")
pseudoR2(modeloManual,data_test,"varObjBin")
```

##Selección de variables 


```{r}
# Seleccion de variables "clásica"

null<-glm(varObjBin~1, data=data_train,family=binomial) #Modelo minimo
full<-glm(varObjBin~.-ID, data=data_train,family=binomial) #Modelo maximo, le quitamos las transformaciones


modeloStepAIC<-step(null, scope=list(lower=null, upper=full), direction="both")
summary(modeloStepAIC)
pseudoR2(modeloStepAIC,data_train,"varObjBin")
pseudoR2(modeloStepAIC,data_test,"varObjBin")

modeloBackAIC<-step(full, scope=list(lower=null, upper=full), direction="backward",trace = F)
summary(modeloBackAIC)
pseudoR2(modeloBackAIC,data_train,"varObjBin")
pseudoR2(modeloBackAIC,data_test,"varObjBin") #son iguales

modeloStepBIC<-step(null, scope=list(lower=null, upper=full), direction="both",k=log(nrow(data_train)), trace = F)
summary(modeloStepBIC)
pseudoR2(modeloStepBIC,data_train,"varObjBin")
pseudoR2(modeloStepBIC,data_test,"varObjBin")

modeloBackBIC<-step(full, scope=list(lower=null, upper=full), direction="backward",k=log(nrow(data_train)), trace = F)
summary(modeloBackBIC)
pseudoR2(modeloBackBIC,data_train,"varObjBin")
pseudoR2(modeloBackBIC,data_test,"varObjBin") # son iguales

modeloStepAIC$rank
modeloStepBIC$rank


```

 

## Selección de variables clásica con variables originales y sus interacciones

```{r seleccion variables clasica interacciones}
#Genero interacciones
formInt<-formulaInteracciones(todo[,c(1:23,30)],24)#en el subconjunto de las vbles. originales, la objetivo está en la columna 17
fullInt<-glm(formInt, data=data_train,family=binomial)

modeloStepAIC_int<-step(null, scope=list(lower=null, upper=fullInt), direction="both")
summary(modeloStepAIC_int)
pseudoR2(modeloStepAIC_int,data_train,"varObjBin")
pseudoR2(modeloStepAIC_int,data_test,"varObjBin") 

modeloStepBIC_int<-step(null, scope=list(lower=null, upper=fullInt), direction="both",k=log(nrow(data_train)))
summary(modeloStepBIC_int)
pseudoR2(modeloStepBIC_int,data_train,"varObjBin")
pseudoR2(modeloStepBIC_int,data_test,"varObjBin") 

modeloStepAIC_int$rank
modeloStepBIC_int$rank


```
Claramente mejor el BIC que el AIC.

## Selección de variables clásica con variables originales y transformaciones y sus interacciones

Aplicamos ahora la función de interacciones con todas las transformaciones obteniendo el set más completo de efectos.

```{r  }
#Trans e interacciones
formIntT<-formulaInteracciones(todo,30)
fullIntT<-glm(formInt, data=data_train,family=binomial)

modeloStepAIC_transInt<-step(null, scope=list(lower=null, upper=fullIntT), direction="both")
summary(modeloStepAIC_transInt)
pseudoR2(modeloStepAIC_transInt,data_train,"varObjBin")
pseudoR2(modeloStepAIC_transInt,data_test,"varObjBin") # se parece el valor a los int sin transf

modeloStepBIC_transInt<-step(null, scope=list(lower=null, upper=fullIntT), direction="both",k=log(nrow(data_train)), trace = F)
summary(modeloStepBIC_transInt)
pseudoR2(modeloStepBIC_transInt,data_train,"varObjBin")
pseudoR2(modeloStepBIC_transInt,data_test,"varObjBin") # 

modeloStepAIC_transInt$rank 
modeloStepBIC_transInt$rank

```


## Evaluación por validación cruzada repetida de los modelos se selección clásica

```{r }
## Pruebo los mejores de cada con validacion cruzada repetida

#copia de la variable original
auxVarObj<-todo$varObjBin

#formateo la variable objetivo para que funcione el codigo
todo$varObjBin<-make.names(todo$varObjBin) 
total<-c()
modelos<-sapply(list(modeloManual,modeloStepAIC,modeloStepBIC,modeloStepBIC_int,modeloStepBIC_transInt),formula)
for (i in 1:length(modelos)){
  set.seed(1712)
  vcr<-train(as.formula(modelos[[i]]), data = todo,
             method = "glm", family="binomial",metric = "ROC",
             trControl = trainControl(method="repeatedcv", number=5, repeats=20,
                                      summaryFunction=twoClassSummary,
                                      classProbs=TRUE,returnResamp="all")
  )
  total<-rbind(total,data.frame(roc=vcr$resample[,1],modelo=rep(paste("Modelo",i),
                                                                  nrow(vcr$resample))))
}
#boxplot(roc~modelo,data=total,main="Área bajo la curva ROC")  
```




```{r metricas validacion cruzada}
#vemos el número de parametros
length(coef(modeloStepBIC_int))
formula(modeloStepBIC_int)
```



# Esquema de selección de variables por Lasso


```{r Lasso}
## LASSO, lo hacemos sin interacciones pues, de lo contrario, puede coger interacciones y no las variables que las forman
y <- as.double(as.matrix(data_train[, 24]))
x<-model.matrix(varObjBin~., data=data_train)[,-1]#no cambiar el -1
set.seed(1712)
cv.lasso <- cv.glmnet(x,y,nfolds=5)
plot(cv.lasso)
```


Este es el comportamiento de lambda y el intervalo de 1se. Mostramos lo coeficiente.

```{r}
(betas<-coef(cv.lasso, s=cv.lasso$lambda.1se))
```
Note que:

- Hay una buena cantidad de variables que influyen en nuestro modelos, las de punto tienen una distripución sobre los parámetros que no vale la pena. Habia considerado que la fatura mensual influiría y al parecer no. Con seguridad, las variables 

```{r}
#pruebo un primer modelo sin las transformadas
modeloInicial<-glm(varObjBin~.,data=data_train[,-c(1)],family=binomial)
summary(modeloInicial)
```



Consultamos los valores de pseudoR2 en los conjuntos de training y test,

```{r}
pseudoR2(modeloInicial,data_train,"varObjBin")
pseudoR2(modeloInicial,data_test,"varObjBin")
modeloInicial$rank #número de parámetros

impVariablesLog(modeloInicial,"varObjBin") 
#si los datos de entrenamiento, no se llaman "data_train", hay que indicarlo

```


En el gráfico se ordenan las aportaciones al pseudoR2 de las distintas variables teniendo Contrato como la gran ganadora ya que aporta muchísimo más que cualquiera.

Ahora, considremos un modelo con las 3 primeras variables, pues presentan incidencias sobre la variable objetivo. 

```{r}
#pruebo uno sencillo con 3 variables
#glm() modelos lineales generalizados 
modelo2<-glm(varObjBin~Contrato+Int_serv+Antiguedad,
             data=data_train,family=binomial)
summary(modelo2)
pseudoR2(modelo2,data_train,"varObjBin")
pseudoR2(modelo2,data_test,"varObjBin")
modelo2$rank
```
Es un buen modelo, significativo en cuanto a sus parametros , indicando pseudoR2 en test es baja respecto a training lo que quiere decir que puede tener una mayor capacidad predictiva de generalización.

Vamos viendo que pasa con 5 variables y sus interacciones,  


```{r}
#fijandome en la importancia de las variables, 
#selecciono aquellas por encima de las aleatorias
modelo3<-glm(varObjBin~Contrato+Int_serv+Antiguedad+Seguridad+Fact_sinPapel,
             data=data_train,family=binomial)
summary(modelo3)

pseudoR2(modelo3,data_train,"varObjBin")#es un poquito peor que el anterior,
#pero el n. de parametros es casi la mitad
pseudoR2(modelo3,data_test,"varObjBin")
modelo3$rank

```

El modelo en parámetros aumentó, pero sigue generalizando su capacidad predictiva pseudoR2 para test.  

Veamos que pasa con variables continuas, como FacturaTotal, FacturaMes, 

```{r}
#fijandome en la importancia de las variables, 
#selecciono aquellas por encima de las aleatorias
modelo4<-glm(varObjBin~Contrato+Int_serv+Antiguedad+Seguridad+Fact_sinPapel+FacturaTotal+FacturaMes,
             data=data_train,family=binomial)
summary(modelo4)

pseudoR2(modelo4,data_train,"varObjBin")#es un poquito peor que el anterior,
#pero el n. de parametros es casi la mitad
pseudoR2(modelo4,data_test,"varObjBin")
modelo4$rank

```

Vemos que el modelo se mueve bastante en Training, ademas que tuvo ligero aumentos , junto con sus parámetros.La variable Factura Total no aporta tanto al modelo.

Veamos que pasa con la interación sugerida por selección de variables clásica, 

```{r}
#pruebo uno con la interacción de alguna continua como pH y etiqueta
modelo5<-glm(varObjBin~Contrato+Int_serv+Contrato*Antiguedad,
             data=data_train,family=binomial)
summary(modelo5)
pseudoR2(modelo5,data_train,"varObjBin")#No parece muy buena idea
pseudoR2(modelo5,data_test,"varObjBin")
modelo3$rank
```



## Evaluación de los modelos por validación cruzada repetida

```{r}
#Validacion cruzada repetida para elegir entre todos

#copia de la variable original
auxVarObj<-todo$varObjBin

#formateo la variable objetivo para que funcione el codigo
todo$varObjBin<-make.names(todo$varObjBin) 

total<-c()
modelos<-sapply(list(modeloInicial,modelo2,modelo3,modelo4,modelo5),formula)
for (i in 1:length(modelos)){
  set.seed(1712)
  vcr<-train(as.formula(modelos[[i]]), data = todo,
             method = "glm", family="binomial",metric = "ROC",
             trControl = trainControl(method="repeatedcv", number=5, repeats=20,
                                      summaryFunction=twoClassSummary,
                                      classProbs=TRUE,returnResamp="all")
  )
  total<-rbind(total,data.frame(roc=vcr$resample[,1],modelo=rep(paste("Modelo",i),
                                                                  nrow(vcr$resample))))
}
boxplot(roc~modelo,data=total,main="Área bajo la curva ROC") 
```

Podemos decir que todos los modelos son buenos, tiene un ROC en torno a 0.83 y pues la diferencia entre ellos son muy sutiles. 

Veamos los valores medios y la desviación respecto a la media de todos los modelos y veamos su comportamiento. 

```{r}
aggregate(roc~modelo, data = total, mean) 
aggregate(roc~modelo, data = total, sd) 
```

```{r}
#recupero la variable objetivo en su formato
todo$varObjBin<-auxVarObj

#miro el numero de parametros
modeloInicial$rank
modelo2$rank 
modelo3$rank
modelo4$rank
modelo5$rank
```
Podemos decir que, entre ellos las diferencias son muy ligeras y que cualquier modelo podria ayudarnos,para mi, el que mejor incidencia tiene es el modelo 3  o el modelo 5 que tiene el top de las variables que más repercuten. 


## Punto de corte óptimo para la probabilidad estimada

```{r}
## BUscamos el mejor punto de corte

#gráfico de las probabilidades obtenidas
hist_targetbinaria(predict(modelo3, newdata=data_test,type="response"),data_test$varObjBin,"probabilidad")
```
- Azul: Distribución de probabilidades estimadas para los 1. Está mucho más repartida
- Rojo : Distribución de probabilidades estimadas para los 0. Su densidad apunta para valores muy bajos 

Note que, el modelo como lo habiamos planteado, tiene dificultades pra reconocer a los 1. 

El punto de corte donde la mayor densidad se concentra en la distribición de probabilidades estimadas para cero se aproxima a 0.3.

```{r}
#probamos dos
sensEspCorte(modelo3,data_test,"varObjBin",0.3,"1")
sensEspCorte(modelo3,data_test,"varObjBin",0.57,"1")

```

Con el punto de corte en 0.3 el accuracy es de 75% estará bien clasficada. En un 76% el modelo tiene la capacidad de reconocer a los 1 y en un 74% tiene la capacidad de reconocer a los cero. Muy parejo. ¿Que significa?(Pendiente)

Coloquemos ahora, una rejilla de puntos de corte posibles entre 0 y 1 y valoremos cual criterio maximiza el accurazy. 


```{r}
## generamos una rejilla de puntos de corte
posiblesCortes<-seq(0,1,0.01)
rejilla<-data.frame(t(rbind(posiblesCortes,sapply(posiblesCortes,function(x) 
sensEspCorte(modelo3,data_test,"varObjBin",x,"1")))))
rejilla$Youden<-rejilla$Sensitivity+rejilla$Specificity-1
plot(rejilla$posiblesCortes,rejilla$Youden)
plot(rejilla$posiblesCortes,rejilla$Accuracy)
rejilla$posiblesCortes[which.max(rejilla$Youden)]
rejilla$posiblesCortes[which.max(rejilla$Accuracy)]
```


Veamos ahora los coeficientes del modelo ganador.

```{r}
# Vemos los coeficientes del modelo ganador
coef(modelo3)
```

Veamos la matriz de confusión en el conjunto de test,enfrentamos lo que hemos dicho con la verdad verdadera. 

```{r}
# Generar el factos con las clases estimadas en test
pred_test<-factor(ifelse(predict(modelo3,data_test,type = "response")>0.3,1,0))

# Tablas marginales
table(pred_test)
table(data_test$varObjBin)

# Matriz de confusión
confusionMatrix(pred_test,data_test$varObjBin, positive = '1')
```
Observe que:

- El modelo reconoce a 249 de 337  (1) y a 711  de 933 (0).
- La diagonal principal de la matriz de confusion nos da una pista de un buen modelo. 

## Interpretación de parámetros del modelo logístico

```{r}
# Ajustamos el modelo a datos completos 
modeloC <- glm(formula(modelo3),data=todo,family=binomial)
summary(modeloC)
```
Para calcular el OR, es decir la probabilidad de evento sobre la probabilidad de no evento, tomemos la siguiente función y aplicando la exponencial por ser la inversa, tenemso que, 


```{r}
# Odds ratios
epiDisplay::logistic.display(modeloC)
```

Conclusiones del modelo, 

-La probabilidad de Fuga respecto a la no Fuga se reduce en un 74% en un Cliente con Contrato por dos años con respecto a la de un cliente con contraro mes a mes.

- Cada aumento unitario de la **Antiguedad** produce una reducción de probabilidad de Fuga del 3%.

- La probabilidad de no fuga de un Cliente con Internet Fibra óptica es 2.88 veces superior a la de un Cliente con internet DSL. 


##Aplicación de modelo a FugaClientes_test

```{r}

data_test<-readRDS("C:/Users/Laura/Dropbox/UCM/Mineria_y_modelizacion_1/Tarea/FugaClientes_test.RDS")

```


```{r}
# Generar el factos con las clases estimadas en test
pred_test<-factor(ifelse(predict(modelo3,data_test,type = "response")>0.3,1,0))

# Tablas marginales
table(pred_test)
table(data_test$varObjBin)

saveRDS(cbind(data_test[1],pred_test),"FugaPredict_LauraPineros.RDS")

```




